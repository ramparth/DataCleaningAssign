iris[,1]
mean(iris[1])
sapply(iris[,1],mean)
sapply(iris[1,],mean)
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
with(mtcars, tapply(mpg, cyl, mean))
sapply(iris@Sepal.Length,mean)
iris
split(iris$Species,iris$Sepal.Length)
sapply(split(iris$Species,iris$Sepal.Length),mean)
sapply(split(iris$Sepal.Length,iris$Species),mean)
with(mtcars, tapply(mpg, cyl, mean))
mean(mtcars$mpg, mtcars$cyl)
apply(mtcars, 2, mean)
sapply(split(iris$Sepal.Length,iris$Species),mean)
x<-sapply(split(iris$Sepal.Length,iris$Species),mean)
x[virginica]
x["virginica""]
""
x["virginica"]
x<- 1:20
x
cachemean(x,makevector)
ls()
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/Trial.R')
ls()
cachemean(x,makevector)
y<- makevector(x)
y<- makeVector(x)
y
cachemean(x,makeVector)
cachemean(y,mean)
y
y[1]
y$getmean
y$set
y$set()
y$set(x)
y$get()
y$setmean(y)
y$getmean()
a<-1:50
y$set(a)
y$get()
y$setmean(y)
y$getmean()
cachemean(y)
z<-solve(y)
tempMatrix <- matrix(1:25,nrow=5,ncol=5)
z<-solve(tempMatrix)
?solve
a
hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
hilbert
hilbert(50)
class(hilbert)
z<-hilbert(50)
class(z)
z1<-solve(z)
z<-hilbert(h8); h8
z<-hilbert(8); h8
z<-hilbert(8)
z8<-solve(z)
z8
z
outer(25,25,"+")
outer(20,21,"+")
hilbert <- function(n) { i <- 1:n; i / i+1  }
z<-hilbert(8)
z8<-solve(z)
z
read.csv("TrialData.csv")
read.csv("/ProgrammingAssignment2/TrialData.csv")
read.csv("./ProgrammingAssignment2/TrialData.csv")
z<-read.csv("./ProgrammingAssignment2/TrialData.csv",header = FALSE)
z
z8<-solve(z)
nrow(z)
ncol(z)
hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, "+") }
z<-hilbert(18)
z8<-solve(z)
z<-hilbert(10)
z8<-solve(z)
z<-read.csv("./ProgrammingAssignment2/TrialData.csv",header = FALSE)
z
z8<-solve(z)
class(z)
dim(z)
?solve
sh8
z8
z
z8<-solve(z)
z[8,8]
z<-read.csv("./ProgrammingAssignment2/TrialData.csv",header = FALSE)
z8<-solve(z)
z<-read.csv("./ProgrammingAssignment2/TrialData.csv",header = FALSE)
z[8,8]
z8<-solve(z)
z4<-lapply(z,mean)
z4
z8<-solve(z4)
z4<-lapply(z[,cols],mean)
z4<-sapply(z,mean)
z4
y
y$get
y$get()
y$getmean()
x
a
y
y$get
y$get()
m
y$getmean()
y$setmean(a)
y$getmean()
y$setmean(mean(a)
)
y$getmean()
cachemean(a)
cachemean(y)
y$setmean(a)
cachemean(y)
z<-read.csv("./ProgrammingAssignment2/TrialData.csv",header = FALSE)
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
makeCacheMatrix(z)
mat1<-makeCacheMatrix(z)
mat1
mat1$get()
cacheSolve(mat1)
cacheSolve
mat1
mat1$get()
cacheSolve(mat1)
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1 <- makeCacheMatrix(a)
mat1
mat1$get()
x
mat1$set(z)
mat1$get()
mat1$getinverse()
cacheSolve(mat1)
data<-mat1$get()
md <- solve(data)
mat1$setinverse(md)
mat1$getinverse()
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
m<-NULL
mat1<-NULL
mat1 <- makeCacheMatrix(z)
cacheSolve(mat1)
mat1<-NULL
mat1 <- makeCacheMatrix(x)
mat1$set(z)
mat1$get()
cacheSolve(mat1)
mat1$setinverse(z)
mat1$getinverse
mat1$getinverse()
cacheSolve(mat1)
m
n<-NULL
y
y<-NULL
x<-NULL
z<-NULL
mat1<-NULL
mat1<-makeCacheMatrix(x)
mat1$get()
mat1$set(z)
mat1$get()
z
z<-read.csv("./ProgrammingAssignment2/TrialData.csv",header = FALSE)
mat1$set(z)
mat1$get()
mat1$getinverse()
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
message("1"+ c(1:3))
message("1"& c(1:3))
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
cacheSolve(mat1)
m
message("ABC", "DEF")
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
cacheSolve(mat1)
data
class(data)
class(m)
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
cacheSolve(mat1)
mat2 <- solve(mat1$get())
mat2
mat2<-NULL
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1$getinverse()
cacheSolve(mat1)
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1<-NULL
x
y
z
m
mat1<-makeCacheMatrix(x)
mat1$get()
mat1$set(a)
mat1$get()
m
mat1$setinverse(a)
mat1$setinverse(z)
m
mat1$get()
mat1$getinverse()
mat1$set(z)
mat1$get()
mat1$setinverse(z)
mat1$getinverse()
m
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1$set(z)
m
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1<-NULL
y
z
x
mat1<-makeCacheMatrix(x)
m
mat1$set(z)
m
m<-NULL
mat1$set(z)
m
mat1$setinverse(z)
m
cacheSolve(mat1)
m
m
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1$setinverse(z)
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1<-NULL
mat1<-makeCacheMatrix(x)
mat1$set(z)
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/ProgrammingAssignment2/cachematrix.R')
mat1$set(z)
mat1<-NULL
mat1$set(z)
mat1<-makeCacheMatrix(x)
mat1$get()
mat1$set(z)
mat1$setinverse(z)
mat1$set(z)
m
library(swirl)
swirl()
library(swirl)
swirl()
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, unique, character(1))
ok()
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
flags
tapply(flags$population, flags$landmass, summary)
?sample
sample(1:6, 4, replace = TRUE)
(1/6)^4 = 0.00077
sample(1:6, 4, replace = TRUE,prob=0.00077)
ok()
sample(1:6, 4, replace = TRUE)
sample(1:10, 4)
sample(1:20, 10)
LETTERS
sample(LETTERS)
flips <- sample(c(0,1),100,replace=TRUE,prob=c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10)
rnorm(10, mean = 100, sd = 25)
?rpois
rpois(5,mean(10))
rpois(5, 10)
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
q()
getwd()
fileURL<- "http://www.hasbro.com/equestria-girls/en_US/girls/twilight-sparkle.cfm"
download.file(fileURL,datafile="Eg_twilight-sparkle.JSON")
download.file(fileURL,datafile="Eg_twilight-sparkle.csv")
download.file(fileURL,destfile="Eg_twilight-sparkle.JSON")
fileURL<- "http://www.hasbro.com/equestria-girls/en_US/girls/"
download.file(fileURL,destfile="Eg_twilight-sparkle.JSON")
fileURL<- "http://www.hasbro.com/equestria-girls/en_US/girls/twilight-sparkle.cfm?accessType=DOWNLOAD"
download.file(fileURL,destfile="Eg_twilight-sparkle.JSON")
fileURL<- "http://www.hasbro.com/equestria-girls/en_US/girls/twilight-sparkle.cfm?accessType=DOWNLOAD"
download.file(fileURL,destfile="Eg_twilight-sparkle.JSON")
fileURL<- "http://www.hasbro.com/equestria-girls/en_US?accessType=DOWNLOAD"
download.file(fileURL,destfile="Eg_twilight-sparkle.JSON")
library(XML)
install.packages("XML")
install.packages("jsonlite")
install.packages("xlsx")
library(data.table)
install.packages("data.table")
library(data.table)
exit
q()
library("swirl")
swirl()
swirl()
library(swirl)
swirl()
getwd()
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/Temp_DownloadFile.R')
source('C:\Ramesh\Personal\Training\DataScience\R\RStudio\swirl_courses\Getting_and_Cleaning_Data/*.R')
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/swirl_courses/Getting_and_Cleaning_Data/*.R')
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/swirl_courses/Getting_and_Cleaning_Data/*')
source('C:/Ramesh/Personal/Training/DataScience/R/RStudio/swirl_courses/Getting_and_Cleaning_Data/Tidying_Data_with_tidyr/*.R')
library(swirl)
swirl()
?InstallCourses
install_from_swirl("Getting_and_Cleaning_Data", dev = FALSE, mirror = "github")
install_from_swirl("Getting_and_Cleaning_Data", dev = FALSE, mirror = "github")
swirl()
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf,10)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, -(X:size))
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1",country == "US")
?Comparison
filter(cran, r_version <= "3.0.2",country == "IN")
filter(cran, country== "US" || country == "IN")
filter(cran, country== "US" | country == "IN")
filter(cran, size > 100500,r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
select(cran,!is.na(r_version))
filter(cran,!is.na(r_version))
cran2 <- select (cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country,desc(r_version), ip_id)
cran3 <- select(cran,ip_id, package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20,size_gb=size_mb/2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package,mean(size))
?n
submit()
pack_sum
q()
swirl()
library(swirl)
swirl()
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts,count)
top_counts_sorted <- arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs =0.99)
filter(pack_sum,unique>465)
top_unique<-filter(pack_sum,unique>465)
view(top_unique<-filter)
View(top_unique<-filter)
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique))
top_unique_sorted <- arrange(top_unique,desc(unique))
top_counts_sorted <- arrange(top_counts,desc(count))
top_unique_sorted<-arrange(top_unique, desc(unique))
skip
arrange(top_unique, desc(unique))
info()
top_unique_sorted<-arrange(top_unique,unique)
top_unique
top_unique<-filter(pack_sum,unique>465)
top_unique_sorted<-arrange(top_unique, desc(unique))
view(top_unique_sorted)
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
play()
select(cran,ip_id,country,package,size)
nxt()
submit()
submit()
submit()
submit()
play()
print(mutate(cran,size_mb=size / 2^20))
nxt()
submit()
submit()
reset()
submit()
submit()
submit()
q()
library(swirl)
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
quit()
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlcode=readLines(con)
close(con)
htmlcode
htmlcode[10]
nchar(htmlcode[10])
nchar(htmlcode[20])
nchar(htmlcode[30])
nchar(htmlcode[100])
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
?setInternet2
setInternet2(TRUE)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
setInternet2(use=TRUE)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for","q5.csv")
getwd()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for","q5.dat")
con <- url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for")
htmlcode=readLines(con)
close(con)
htmlcode
htmlcodeDF <- data.frame(htmlcode)
htmlcodeDF
htmlcodeDF[4]
htmlcodeDF[,4]
htmlcodeDF[4,]
htmlcodeDF[,4]
exit
q()
q()
library(swirl)
swirl()
res<- gather(students2,sex_class,value)
res<- gather(students2,sex_class,value,-grade)
res<- gather(students2, sex_class, count, -grade)
res
q()
?table
source('C:/Ramesh/Personal/Training/DataScience/DataCleaning/Project/UCI HAR Dataset/run_analysis.R')
run_analysis()
setwd("C:/Ramesh/Personal/Training/DataScience/DataCleaning/Project/UCI HAR Dataset")
run_analysis()
source('C:/Ramesh/Personal/Training/DataScience/DataCleaning/Project/UCI HAR Dataset/run_analysis.R')
run_analysis()
source('C:/Ramesh/Personal/Training/DataScience/DataCleaning/Project/UCI HAR Dataset/run_analysis.R')
run_analysis()
?write.table
source('C:/Ramesh/Personal/Training/DataScience/DataCleaning/Project/UCI HAR Dataset/run_analysis.R')
run_analysis()
